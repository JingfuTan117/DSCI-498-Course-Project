# DSCI-498-Course-Project

Project Name:
Superquantile-based Deep Generative Learning

Project Abstract: 
The performance of generative models is highly dependent on the training process, where data quality and distribution play a crucial role. However, standard training methods may lead to instability and poor model performance when data exhibit heterogeneous distributions. To address this challenge, distributionally robust optimization methods, such as superquantile-based learning, have been proposed to enhance the robustness of machine learning or deep learning models. In this work, I aim to integrate superquantile-based loss functions into generative learning models to improve their resilience to risk-sensitive scenarios and data heterogeneity. By doing so, I seek to develop a more distributionally robust generative model capable of producing reliable outputs under diverse and uncertain data conditions.

Dataset:
1. MNIST with Class Imbalance
2. CelebA (Face Dataset)
3. Medical Imaging Dataset